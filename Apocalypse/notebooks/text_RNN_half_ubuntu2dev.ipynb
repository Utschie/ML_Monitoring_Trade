{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本模型是textRNN_half_ubuntu的第2版\n",
    "'''\n",
    "1.改用最大值，均值和最小值的拼接向量做输入，弃用tsvd和max2vec\n",
    "2.使用平衡后的训练集和测试集\n",
    "3.模型加入BN层\n",
    "'''\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from torch.nn.utils.rnn import pad_sequence#用来填充序列\n",
    "import time\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pywick.optimizers.nadam import Nadam#使用pywick包里的nadam优化器\n",
    "from torch.optim import lr_scheduler\n",
    "with open('/home/jsy/data/cidlist_complete.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    cidlist = [row[1] for row in reader]#得到cid对应表\n",
    "cidlist = list(map(float,cidlist))#把各个元素字符串类型转成浮点数类型\n",
    "class DataLoaderX(DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())\n",
    "class BisaiDataset(Dataset):#数据预处理器\n",
    "    def __init__(self,filepath):#filepath是个列表\n",
    "        with open(filepath,'r') as f:#读取filepath文件并做成filelist列表\n",
    "            self.filelist = []\n",
    "            for line in f:\n",
    "                self.filelist.append(line.strip('\\n'))\n",
    "        self.lablelist = pd.read_csv('/home/jsy/data/lablelist.csv',index_col = 0)#比赛id及其对应赛果的列表\n",
    "        self.lables = {'win':0,'draw':1,'lose':2}#分类问题要从0开始编号,而且要对应好了表中的顺序编，\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #todo\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        #这里需要注意的是，第一步：read one data，是一个dat\n",
    "        data_path = self.filelist[index]\n",
    "        bisai_id = int(re.findall(r'/(\\d*?).csv',data_path)[0])\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        data = self.csv2frame(data_path)\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        lable = self.lablelist.loc[bisai_id].result\n",
    "        lable = self.lables[lable]\n",
    "        return data,lable      \n",
    "       \n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def csv2frame(self,filepath):#给出单场比赛的csv文件路径，并转化成帧列表和对应变帧时间列表，以及比赛结果\n",
    "        data = pd.read_csv(filepath)#读取文件\n",
    "        data = data.drop(columns=['league','zhudui','kedui','companyname'])#去除非数字的列\n",
    "        frametimelist=data.frametime.value_counts().sort_index(ascending=False).index#将frametime的值读取成列表\n",
    "        framelist =list()#framelist为一个空列表,长度与frametimelist相同,一定要规定好具体形状和float类型，否则dataloader无法读取\n",
    "        '''\n",
    "        此处两个循环算法太慢，用pandas更慢，完全抛弃pandas后，数据处理速度从109秒降到了10秒，降到10秒后cpu利用率20%，再往上提也提不上去了，可能需要C++或C来写了\n",
    "        '''\n",
    "        new_data = np.array(data)\n",
    "        lables = new_data[:,0]\n",
    "        if len(frametimelist)>250:#如果总帧数大于250,则随机挑选250，若不足250,则在后面处理vectensor时补0\n",
    "            frametimelist = [frametimelist[0]]+random.sample(list(frametimelist)[1:-1],248)+[frametimelist[-1]]#如果长度大于500,保留头尾，并在中间随机抽取498个，共计500个\n",
    "            frametimelist.sort(reverse=True)#并降序排列\n",
    "        for i in frametimelist:\n",
    "            state = new_data[lables==i]#从第一次变盘开始得到当次转移\n",
    "            #state = np.array(state)#不必转成numpy多维数组，因为已经是了\n",
    "            state = np.delete(state,(0,1), axis=-1)#去掉frametime和cid\n",
    "            #在填充成矩阵之前需要知道所有数据中到底有多少个cid\n",
    "            max_min = np.concatenate((state.max(axis=0)[0:4],state.mean(axis=0)[0:4],state.min(axis=0)[0:4]),axis=0)\n",
    "            framelist.append(max_min)\n",
    "        frametimelist = np.array(frametimelist)\n",
    "        vectensor = np.array(framelist)\n",
    "        len_frame = vectensor.shape[0]\n",
    "        if len_frame<250:\n",
    "            vectensor = np.concatenate((np.zeros((250-len_frame,12),dtype=np.float64),vectensor),axis=0)#如果不足500，则在前面用0填充\n",
    "        vectensor = torch.from_numpy(vectensor)\n",
    "        return vectensor#传出一个帧列表,也可以把frametimelist一并传出来，此处暂不考虑位置参数的问题\n",
    "    \n",
    "\n",
    "\n",
    "class Lstm(nn.Module):#在模型建立之处就把它默认初始化\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size=12, \n",
    "                                hidden_size=250,#选择对帧进行保留首尾的均匀截断采样\n",
    "                                num_layers=1,#暂时就只有一层\n",
    "                                bidirectional=True)\n",
    "        nn.init.orthogonal_(self.encoder.weight_ih_l0)\n",
    "        nn.init.orthogonal_(self.encoder.weight_hh_l0)\n",
    "        nn.init.constant_(self.encoder.bias_ih_l0,0.0)\n",
    "        nn.init.constant_(self.encoder.bias_hh_l0,0.0)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(1000, 250),#把LSTM的输出\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(250, 3)\n",
    "        )\n",
    "        nn.init.normal_(self.decoder[0].weight,mean=0.0)\n",
    "        nn.init.constant_(self.decoder[0].bias, 0.0)\n",
    "        nn.init.normal_(self.decoder[3].weight,mean=0.0)\n",
    "        nn.init.constant_(self.decoder[3].bias, 0.0)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        output, _= self.encoder(inputs.permute(1,0,2))#inputs需要转置一下再输入lstm层，因为pytorch要求第0维为长度，第二维才是batch_size\n",
    "        encoding = torch.cat((output[0], output[-1]), -1)#双向的lstm，就把两个都放进去\n",
    "        return self.decoder(encoding)#把最后一个时间步的输出输入MLP\n",
    "\n",
    "\n",
    "def get_parameter_number(model):#参数统计\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/jsy/balanced_train_path.txt'\n",
    "test_path = '/home/jsy/balanced_test_path.txt'\n",
    "dataset = BisaiDataset(train_path)#训练集\n",
    "test_set = BisaiDataset(test_path)#验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoaderX(dataset, 64 ,shuffle=True,num_workers=4,pin_memory=True)#num_workers>0情况下无法在交互模式下运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsy/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y  = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9200, 2.1000, 3.3000,  ..., 2.1000, 3.3000, 3.3000],\n",
       "        [0.9500, 2.1000, 3.4000,  ..., 1.9500, 3.2000, 3.3000],\n",
       "        [0.9800, 2.1000, 3.5500,  ..., 1.9100, 3.2000, 3.3000],\n",
       "        ...,\n",
       "        [0.9800, 2.1000, 3.6000,  ..., 1.8000, 2.9000, 3.0500],\n",
       "        [0.9800, 2.1000, 3.6000,  ..., 1.8000, 2.9000, 3.0500],\n",
       "        [0.9800, 2.1000, 3.6000,  ..., 1.8000, 2.9000, 3.0500]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 0, 2, 1, 0, 2, 2, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 2, 1, 1, 0,\n",
       "        0, 2, 1, 1, 0, 1, 0, 2, 1, 1, 1, 2, 0, 0, 1, 2, 0, 1, 2, 0, 0, 2, 2, 2,\n",
       "        1, 1, 2, 1, 2, 1, 2, 2, 2, 0, 0, 2, 1, 2, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
